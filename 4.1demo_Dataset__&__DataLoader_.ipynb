{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PtVSqdmTwIRk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "6ab3c804-a163-4bb3-84bc-ef0fd3c1631f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n1) Dataset in PyTorch\\n\\nA Dataset is an abstraction that represents your data (features + labels).\\n\\nIt tells PyTorch how to access and return individual samples.\\n\\nThere are two main types of datasets:\\n\\nBuilt-in datasets â€“ available in torchvision.datasets (like MNIST, CIFAR-10).\\n\\nCustom datasets â€“ you create your own by subclassing torch.utils.data.Dataset.\\n\\n2)\\nDataLoader in PyTorch\\n\\nThe DataLoader wraps around a Dataset and provides:\\n\\nBatching (splitting data into mini-batches).\\n\\nShuffling (randomizing order of samples).\\n\\nParallel loading (using multiple workers to speed up loading).\\n\\n\\n\\nDataset is the shape of your data: how to index it and how to turn one sample into tensors.\\nDataLoader is the engine that turns those samples into efficient batches (shuffle, parallel I/O, prefetch, collate)\\n\\nConcrete technical benefits & features\\n\\nBatching (batch_size) â€” groups samples into tensors.\\n\\nShuffling (shuffle=True) â€” random order per epoch (or use a Sampler for custom behavior).\\n\\nParallelism (num_workers) â€” spawn worker processes to load/transform samples in parallel (avoids Python GIL bottleneck for I/O/CPU-bound transforms).\\n\\nPrefetch & pinning (pin_memory=True) â€” speeds hostâ†’GPU transfer; use tensor.to(device, non_blocking=True).\\n\\nCollate function (collate_fn) â€” custom compose of samples into a batch (useful for padding sequences).\\n\\nSamplers â€” exact control over indexing/sharding (e.g., uniform sampling, weighted sampling, distributed).\\n\\nIterableDataset â€” for streaming data sources (logs, sockets, huge corpora).\\n\\npersistent_workers â€” keeps worker processes alive across epochs to reduce startup overhead.\\n\\ngenerator + worker_init_fn â€” deterministic shuffling & reproducible worker RNGs.\\n\\n\\n3. Other Important Parameters of DataLoader\\n\\nHereâ€™s a cheat sheet with their use cases ðŸš€:\\n\\n\\n| Parameter                | What it does                                 | Why/When to use                                                                     |\\n| ------------------------ | -------------------------------------------- | ----------------------------------------------------------------------------------- |\\n| **`batch_size`**         | Number of samples per batch                  | Larger â†’ faster training but more memory use. Smaller â†’ more stable updates.        |\\n| **`shuffle`**            | Randomizes order every epoch                 | Important for SGD convergence. Use `False` for evaluation/test.                     |\\n| **`num_workers`**        | Number of parallel worker processes          | More workers â†’ faster data loading (tune based on CPU cores).                       |\\n| **`pin_memory`**         | Copies data into pinned (page-locked) memory | Makes GPU transfer (`.to(device, non_blocking=True)`) faster. Useful for CUDA.      |\\n| **`drop_last`**          | Drops last incomplete batch                  | Useful when batchnorm needs consistent batch size.                                  |\\n| **`sampler`**            | Custom sampling strategy                     | Use for imbalance (WeightedRandomSampler), distributed training, or custom subsets. |\\n| **`collate_fn`**         | Merges list of samples into batch            | Needed for variable-length data (padding, masking, dicts).                          |\\n| **`timeout`**            | Seconds to wait for a worker to fetch data   | Avoids deadlocks in slow/unstable I/O.                                              |\\n| **`worker_init_fn`**     | Function to initialize workers               | Useful for seeding RNG in each worker for reproducibility.                          |\\n| **`generator`**          | Controls randomness in DataLoader            | Useful for reproducibility (deterministic shuffle).                                 |\\n| **`persistent_workers`** | Keeps workers alive between epochs           | Saves worker startup overhead in long training jobs.                                |\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "'''\n",
        "1) Dataset in PyTorch\n",
        "\n",
        "A Dataset is an abstraction that represents your data (features + labels).\n",
        "\n",
        "It tells PyTorch how to access and return individual samples.\n",
        "\n",
        "There are two main types of datasets:\n",
        "\n",
        "Built-in datasets â€“ available in torchvision.datasets (like MNIST, CIFAR-10).\n",
        "\n",
        "Custom datasets â€“ you create your own by subclassing torch.utils.data.Dataset.\n",
        "\n",
        "2)\n",
        "DataLoader in PyTorch\n",
        "\n",
        "The DataLoader wraps around a Dataset and provides:\n",
        "\n",
        "Batching (splitting data into mini-batches).\n",
        "\n",
        "Shuffling (randomizing order of samples).\n",
        "\n",
        "Parallel loading (using multiple workers to speed up loading).\n",
        "\n",
        "\n",
        "\n",
        "Dataset is the shape of your data: how to index it and how to turn one sample into tensors.\n",
        "DataLoader is the engine that turns those samples into efficient batches (shuffle, parallel I/O, prefetch, collate)\n",
        "\n",
        "Concrete technical benefits & features\n",
        "\n",
        "Batching (batch_size) â€” groups samples into tensors.\n",
        "\n",
        "Shuffling (shuffle=True) â€” random order per epoch (or use a Sampler for custom behavior).\n",
        "\n",
        "Parallelism (num_workers) â€” spawn worker processes to load/transform samples in parallel (avoids Python GIL bottleneck for I/O/CPU-bound transforms).\n",
        "\n",
        "Prefetch & pinning (pin_memory=True) â€” speeds hostâ†’GPU transfer; use tensor.to(device, non_blocking=True).\n",
        "\n",
        "Collate function (collate_fn) â€” custom compose of samples into a batch (useful for padding sequences).\n",
        "\n",
        "Samplers â€” exact control over indexing/sharding (e.g., uniform sampling, weighted sampling, distributed).\n",
        "\n",
        "IterableDataset â€” for streaming data sources (logs, sockets, huge corpora).\n",
        "\n",
        "persistent_workers â€” keeps worker processes alive across epochs to reduce startup overhead.\n",
        "\n",
        "generator + worker_init_fn â€” deterministic shuffling & reproducible worker RNGs.\n",
        "\n",
        "\n",
        "3. Other Important Parameters of DataLoader\n",
        "\n",
        "Hereâ€™s a cheat sheet with their use cases ðŸš€:\n",
        "\n",
        "\n",
        "| Parameter                | What it does                                 | Why/When to use                                                                     |\n",
        "| ------------------------ | -------------------------------------------- | ----------------------------------------------------------------------------------- |\n",
        "| **`batch_size`**         | Number of samples per batch                  | Larger â†’ faster training but more memory use. Smaller â†’ more stable updates.        |\n",
        "| **`shuffle`**            | Randomizes order every epoch                 | Important for SGD convergence. Use `False` for evaluation/test.                     |\n",
        "| **`num_workers`**        | Number of parallel worker processes          | More workers â†’ faster data loading (tune based on CPU cores).                       |\n",
        "| **`pin_memory`**         | Copies data into pinned (page-locked) memory | Makes GPU transfer (`.to(device, non_blocking=True)`) faster. Useful for CUDA.      |\n",
        "| **`drop_last`**          | Drops last incomplete batch                  | Useful when batchnorm needs consistent batch size.                                  |\n",
        "| **`sampler`**            | Custom sampling strategy                     | Use for imbalance (WeightedRandomSampler), distributed training, or custom subsets. |\n",
        "| **`collate_fn`**         | Merges list of samples into batch            | Needed for variable-length data (padding, masking, dicts).                          |\n",
        "| **`timeout`**            | Seconds to wait for a worker to fetch data   | Avoids deadlocks in slow/unstable I/O.                                              |\n",
        "| **`worker_init_fn`**     | Function to initialize workers               | Useful for seeding RNG in each worker for reproducibility.                          |\n",
        "| **`generator`**          | Controls randomness in DataLoader            | Useful for reproducibility (deterministic shuffle).                                 |\n",
        "| **`persistent_workers`** | Keeps workers alive between epochs           | Saves worker startup overhead in long training jobs.                                |\n",
        "\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "bacth_size =2\n",
        "means it will fetch two rows\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9ZbiowfL8vV4",
        "outputId": "09784961-28d2-4583-d07a-fe83a5f8e6c8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nbacth_size =2\\nmeans it will fetch two rows\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "import torch"
      ],
      "metadata": {
        "id": "kCCr5T7i80rX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Create a synthetic classification dataset using sklearn\n",
        "X, y = make_classification(\n",
        "    n_samples=10,       # Number of samples\n",
        "    n_features=2,       # Number of features\n",
        "    n_informative=2,    # Number of informative features\n",
        "    n_redundant=0,      # Number of redundant features\n",
        "    n_classes=2,        # Number of classes\n",
        "    random_state=42     # For reproducibility\n",
        ")"
      ],
      "metadata": {
        "id": "Q2CQSNuxY7gs"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkoIGM-pY7dP",
        "outputId": "7fdf0c11-3dfb-4011-efe0-6f8a7e555f03"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.06833894, -0.97007347],\n",
              "       [-1.14021544, -0.83879234],\n",
              "       [-2.8953973 ,  1.97686236],\n",
              "       [-0.72063436, -0.96059253],\n",
              "       [-1.96287438, -0.99225135],\n",
              "       [-0.9382051 , -0.54304815],\n",
              "       [ 1.72725924, -1.18582677],\n",
              "       [ 1.77736657,  1.51157598],\n",
              "       [ 1.89969252,  0.83444483],\n",
              "       [-0.58723065, -1.97171753]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxcKNZkrY7Zw",
        "outputId": "88a8a207-850a-4662-c531-09f1e2f415df"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2z2pbWWY7Wy",
        "outputId": "9ec38b0f-cf8f-41a9-ffd4-3e2ee0cd251a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 0, 1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmX8hdVHY7Tt",
        "outputId": "070cdaf3-dba8-491b-f644-2d13818af37e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the data to PyTorch tensors\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.long)"
      ],
      "metadata": {
        "id": "eD89bEDtY7Ql"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ7Du0KvY7Nr",
        "outputId": "33338c62-e995-4304-c62d-148e153bf63f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0683, -0.9701],\n",
              "        [-1.1402, -0.8388],\n",
              "        [-2.8954,  1.9769],\n",
              "        [-0.7206, -0.9606],\n",
              "        [-1.9629, -0.9923],\n",
              "        [-0.9382, -0.5430],\n",
              "        [ 1.7273, -1.1858],\n",
              "        [ 1.7774,  1.5116],\n",
              "        [ 1.8997,  0.8344],\n",
              "        [-0.5872, -1.9717]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIsUZzCLY7Kx",
        "outputId": "71b7378a-cf4e-4320-bbfc-fab6e2f6fce0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 0, 0, 0, 0, 1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "UstlBHoYY61e"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, features, labels):\n",
        "\n",
        "    self.features = features\n",
        "    self.labels = labels\n",
        "\n",
        "  def __len__(self):\n",
        "\n",
        "    return self.features.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    return self.features[index], self.labels[index]"
      ],
      "metadata": {
        "id": "-nS8L3MhZe4_"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(X, y)"
      ],
      "metadata": {
        "id": "lcMlw4JkZe1l"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K84Giql2ZezD",
        "outputId": "1dfe64c4-4207-450b-cb14-c7d0c6b622bb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBdWgOrDZewn",
        "outputId": "64a221df-0350-45e4-ca44-23c50ae951d1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-2.8954,  1.9769]), tensor(0))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "id": "Wu5_zipdZeuF"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_features, batch_labels in dataloader:\n",
        "\n",
        "  print(batch_features)\n",
        "  print(batch_labels)\n",
        "  print(\"-\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PVy2ZIcZerb",
        "outputId": "afc4ad9d-19b4-4e96-92bf-b32d674fa87e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.0683, -0.9701],\n",
            "        [-0.7206, -0.9606]])\n",
            "tensor([1, 0])\n",
            "--------------------------------------------------\n",
            "tensor([[-2.8954,  1.9769],\n",
            "        [-1.9629, -0.9923]])\n",
            "tensor([0, 0])\n",
            "--------------------------------------------------\n",
            "tensor([[ 1.8997,  0.8344],\n",
            "        [-0.9382, -0.5430]])\n",
            "tensor([1, 1])\n",
            "--------------------------------------------------\n",
            "tensor([[ 1.7273, -1.1858],\n",
            "        [ 1.7774,  1.5116]])\n",
            "tensor([1, 1])\n",
            "--------------------------------------------------\n",
            "tensor([[-0.5872, -1.9717],\n",
            "        [-1.1402, -0.8388]])\n",
            "tensor([0, 0])\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o70fwdWAZepC"
      },
      "execution_count": 35,
      "outputs": []
    }
  ]
}